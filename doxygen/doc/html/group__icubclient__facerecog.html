<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>icub-client: Face Recognition Tutorial: Collecting data and training</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">icub-client
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Face Recognition Tutorial: Collecting data and training</div>  </div>
</div><!--header-->
<div class="contents">

<p>This provides a tutorial on how to create your own face recognition model with <a class="el" href="namespaceSAM.html">SAM</a>.  
<a href="#details">More...</a></p>
<p>This provides a tutorial on how to create your own face recognition model with <a class="el" href="namespaceSAM.html">SAM</a>. </p>
<h2>Prerequisites</h2>
<p>To follow this tutorial you need to have:</p>
<ul>
<li>A <code>SAM_Data_Models</code> folder set up with the structure indicated in <a href="https://github.com/robotology/icub-client/blob/master/src/modules/SAM/README.md">SAM README</a>.</li>
<li>You also need human-sensing-SAM installed and running. Follow the instructions in <a href="https://github.com/dcam0050/human-sensing-SAM/blob/master/README.md">human-Sensing-SAM git repo</a></li>
</ul>
<h2>Data Collection</h2>
<p><b>Step 1</b>: First run:</p>
<pre class="fragment">CLMYarp --from $CLM_MODEL_DIR 
yarp connect &lt;imagePort&gt; /CLM/image/in udp+mjpeg </pre><p>where <code>&lt;imagePort&gt;</code> is the yarp port sending images from a camera. Example one of the icub's eyes <code>/icub/cam/left</code> or a webcam using <code>yarpdev opencv_grabber</code>. The above instructions launch and connect CLMYarp and you should start seeing segmented faces shown on screen. At this point prepare the subject to be recorded in front of the camera being used.</p>
<p><b>Step 2</b>: Go to SAM_Data_Models/Data/&lt;myFacesFolder&gt; directory from the terminal and from this directory run</p>
<pre class="fragment">yarpdatadumper --name /samRecogDumper/faces_in --type image --rxTime --dir &lt;faceName&gt;
yarp connect /CLM/imageSeg/out /samRecogDumper/faces_in udp</pre><p>where <code>&lt;faceName&gt;</code> is the name of the person being recorded. As soon as you make the connection, open your file manager and monitor the amount of images being stored. Terminate <em>yarpdatadumper</em> when the amount of required images is reached: 300-500 images is usually a good amount for training.</p>
<p>Repeat <b>Step 2</b> for each person that is to be trained, changing <code>&lt;faceName&gt;</code> each time such that each person has a separate images folder</p>
<h2>Training</h2>
<p>For training, run <a class="el" href="samSupervisor_8py.html">samSupervisor.py</a> from the command line and connect to it using </p><pre class="fragment">yarp rpc /sam/rpc:i </pre><p>Then if you send a <em>check_all</em> command you should see &lt;myFacesFolder&gt; listed as available for training. To train, send a <em>train &lt;myFacesFolder&gt;</em> command and this will perform the training.</p>
<p>(This page can be edited at <a class="el" href="facerecognitiontutorial_8dox.html">src/doc/facerecognitiontutorial.dox</a>) </p>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed Feb 19 2020 23:45:27 for icub-client by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>icub-client: SAM_Sheffield</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">icub-client
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">SAM_Sheffield </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Authors: Uriel Martinez, Daniel Camilleri, Andreas Damianou, Luke Boorman email: <a href="#" onclick="location.href='mai'+'lto:'+'d.c'+'am'+'ill'+'er'+'i@s'+'he'+'ffi'+'el'+'d.a'+'c.'+'uk'; return false;">d.cam<span style="display: none;">.nosp@m.</span>ille<span style="display: none;">.nosp@m.</span>ri@sh<span style="display: none;">.nosp@m.</span>effi<span style="display: none;">.nosp@m.</span>eld.a<span style="display: none;">.nosp@m.</span>c.uk</a></p>
<p>A Synthetic Autobiographical Memory for the iCub robot. This module contains the core, which implements the high-level functionality, and the drivers which act as middleware between the perceptual system and the core.</p>
<p>Pre-trained Action Recognition model and data can be downloaded <a href="https://drive.google.com/open?id=0B6fkkRLTYjNLbjFFSEZtUmtHNk0">here</a>.</p>
<h2>Features</h2>
<ul>
<li><code>samSupervisor</code> can manage multiple models with great flexibility in training and interacting with models.</li>
<li><code>trainSAMModel</code> allows for the training of multiple, single or temporal models by simply changing the value in the config.ini of the particular model and automates testing of the different types of models.</li>
<li><code>interactionSAMModel</code> also allows for great flexibility in the method of data collection. 3 Methods are currently supported.<ol type="1">
<li><code>continuous</code> : Data is continuously classified by the driver with a buffer of classifications being kept. Each time a classification is queried, the classification buffer decreases in size until it reaches 0 and returns None</li>
<li><code>buffered</code> : In this case, a buffer of the latest n data points are kept and when the classification command is sent, these data points are sent to the driver for classification which is returned immediately.</li>
<li><code>future_buffered</code> : In this case, when a classification request is sent, the future n data points are collected, classified and a classification returned.</li>
</ol>
</li>
</ul>
<p>Setting a model to any one of these data collection methods and also specifying the buffer lengths is done within <code>sensory_level_config.ini</code></p>
<h2>PreRequisites</h2>
<ol type="1">
<li>GPy dependency from <a href="https://github.com/SheffieldML/GPy">https://github.com/SheffieldML/GPy</a>. The best way to include this is:<ol type="a">
<li>clone the GPy repository <a href="https://github.com/SheffieldML/GPy.git">https://github.com/SheffieldML/GPy.git</a></li>
<li>switch to branch "devel"</li>
<li>Include the directory where you cloned GPy in your PYTHONPATH.</li>
<li>Move to the GPy directory and run: "python setup.py install" (try "python setup.py build_ext --inplace" if you want to do the installation in the same directory).</li>
</ol>
</li>
<li>GPyOpt dependency from <a href="https://github.com/SheffieldML/GPy">https://github.com/SheffieldML/GPy</a>. The best way to include this is:<ol type="a">
<li>sudo apt-get install python-pip</li>
<li>pip install gpyopt If this does not work:</li>
</ol>
<ol type="a">
<li>clone the GPyOpt repository <a href="https://github.com/SheffieldML/GPy.git">https://github.com/SheffieldML/GPy.git</a></li>
<li>Include the directory where you cloned GPyOpt in your PYTHONPATH.</li>
<li>Move to the GPyOpt directory and run: "python setup.py develop"</li>
</ol>
</li>
<li>Include the directory <b>ICUBCLIENT_ROOT/src/modules</b> in your PYTHONPATH.</li>
</ol>
<h2>How to use:</h2>
<p>Everything is accessed via <b>samSupervisor</b> which is installed to <b>ICUBCLIENT_DIR</b>.</p>
<p>Connect with <b>samSupervisor</b> via <code>/sam/rpc:i</code> and issue <code>help</code> for a list of all possible commands</p><ul>
<li><code>check_all</code>: Check data and config.ini availabilities for that model, as well as current status (Training or Loaded) and check if model is curently up to date</li>
<li><code>check &lt;modelName&gt;</code>: Check the same points as above but for a single model</li>
<li><code>close &lt;modelName&gt;</code>: Terminates a currently loaded interaction process for the particular model</li>
<li><code>delete &lt;modelName&gt;</code>: Physically deletes the trained model for <code>&lt;modelName&gt;</code></li>
<li><code>help</code>: Provides a list of available commands</li>
<li><code>load &lt;modelName&gt;</code>: Launches an interaction process for the corresponding model. If model already present, reloads model from disk</li>
<li><code>optimise &lt;modelName&gt;</code>: Optimises the parameters of the model via Bayesian Optimisation to achieve the best result. Require GPyOpt to be installed</li>
<li><code>quit</code>: Terminates samSupervisor</li>
<li><code>train &lt;modelName&gt;</code>: Launches a training process for the corresponding model</li>
<li><code>list_callSigns</code>: Compiles a list of currently active callSigns. Where callSigns are the messages that loaded models respond to</li>
</ul>
<p>When a model is loaded, to retrieve a classification of a generation from the model, issue the respective command in the list_callSigns list. There is a timeout of 10 seconds for the response so as not to block the operation of samSupervisor</p>
<h2>Prerequisites to use samSupervisor:</h2>
<p>A folder, <code>&lt;FolderName&gt;</code> which has the following folder structure:</p>
<p><code>&lt;FolderName&gt;</code>:</p><ul>
<li><code>Data:</code><ul>
<li><code>&lt;model1Name&gt;</code></li>
<li><code>&lt;model2Name&gt;</code></li>
<li><code>&lt;model3Name&gt;</code><ul>
<li><code>&lt;model3SubModelName1&gt;</code></li>
<li><code>&lt;model3SubModelName2&gt;</code></li>
<li><code>&lt;model3SubModelNameN&gt;</code></li>
</ul>
</li>
<li><code>&lt;modelMName&gt;</code></li>
</ul>
</li>
<li><code>Models:</code></li>
</ul>
<p>Where <code>&lt;model1Name&gt;</code> and <code>&lt;model2Name&gt;</code> will be modelled as a single model while <code>&lt;model3Name&gt;</code> will have multiple models depending on the number of subfolders in <code>&lt;model3Name&gt;</code>.</p>
<h2>Important Notes:</h2>
<ol type="1">
<li>Each <code>&lt;modelXname&gt;</code> folder must contain data as well as a <code>config.ini</code> which specifies the parameters for training the data found in that folder.</li>
<li>To carry out training, <b>samSupervisor</b> requires at least one <code>&lt;modelXName&gt;</code> folder.</li>
<li>samSupervisor on startup compiles a list of models that are available for training. The models are referenced according their <code>&lt;modelXName&gt;</code></li>
<li><code>&lt;FolderName&gt;/Models</code> is left empty and is used by samSupervisor to store trained models.</li>
<li>You can get an example <code>&lt;FolderName&gt;</code> from <a href="https://drive.google.com/open?id=0B6fkkRLTYjNLbjFFSEZtUmtHNk0">here</a> which contains data and config.ini for Faces and Actions and pre-trained models for Actions</li>
<li>Finally, modify <code>default.ini</code> in <b>samSupervisor</b> context to point to your <code>&lt;FolderName&gt;</code> and comment out models within <code>sensory_level_conf.ini</code> also found in the <b>samSupervisor</b> context which you do not require to run automatically when launching samSupervisor</li>
<li><code>default.ini</code> has 3 options.<ol type="a">
<li>persistence: which defines if windows opened should remain open or close auomatically upon termination. Set to true this is useful to debug training or interaction algorithms.</li>
<li>windowed: which defines if training and interaction functions should spawn a window or not</li>
<li>verbose: defines the level of verbosity of samSupervisor</li>
</ol>
</li>
<li><code>sensory_level_conf.ini</code> specifies which models should be loaded as sections, the names of their respective input/output ports as well as the callsigns which will trigger recall or recognition of that particular model</li>
<li>All <b>PORTS</b>, <b>RPCBASES</b>, and <b>CALLSIGNS</b> must be unique</li>
</ol>
<h2>Breakdown of contents in <a class="el" href="namespaceSAM.html">SAM</a> folder:</h2>
<h4>SAM_Core:</h4>
<ul>
<li>Includes the base classes for SAM_Core and SAM_Driver</li>
<li>Includes <a class="el" href="samSupervisor_8py.html">samSupervisor.py</a>, <a class="el" href="trainSAMModel_8py.html">trainSAMModel.py</a>, <a class="el" href="interactionSAMModel_8py.html">interactionSAMModel.py</a> classes which are installed into ICUBCLIENT_DIR</li>
<li>Implements the core functionality of <a class="el" href="namespaceSAM.html">SAM</a>. This module is the memory system where the already transformed (by SAM_Drivers) perceived signals are compressed and stored in a coherent way. Coherent meaning that audio, visual etc signals are treated in analogous manner. This model is built upon the deep Gaussian process model using GPy, so that high-dimensional, noisy data can be compressed, chunked and "cleaned" automatically in a probabilistic way (ie the model is trying to keep the "relevant" variance in the data and eliminate redundancies in the representation by encoding memories as "clean" and non-redundant signals).</li>
</ul>
<h4>SAM_Drivers:</h4>
<ul>
<li>This folder contains all developed drivers.</li>
<li>These drivers are accessed via the generic trainModel and interactionModel classes which are called from samSupervisor</li>
<li>This module contains the implementation for transforming the raw perceptual signal into preprocessed signal. For example, in the biological brain, the visual cortex is hierarchically processing the visual stimuli before the signal is reaching the brain. In the current implementation, the drivers are doing this work, and currently we have implemented: Faces, Actions</li>
</ul>
<h2>License</h2>
<p>Copyright (C) 2015 WYSIWYD Consortium, European Commission FP7 Project ICT-612139 website: <a href="http://wysiwyd.upf.edu/">http://wysiwyd.upf.edu/</a> Permission is granted to copy, distribute, and/or modify this program under the terms of the GNU General Public License, version 2 or any later version published by the Free Software Foundation.</p>
<p>A copy of the license can be found at icub-client/LICENSE</p>
<p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed Feb 19 2020 23:45:27 for icub-client by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
